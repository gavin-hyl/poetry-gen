{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject 3: Poem Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_dict = {\n",
    "    'shakespeare.txt': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/shakespeare.txt',\n",
    "    'spenser.txt': 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/spenser.txt',\n",
    "    'syllable_dict.txt' : 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/Syllable_dictionary.txt',\n",
    "    # 'about_syllable_dict.docx' : 'https://caltech-cs155.s3.us-east-2.amazonaws.com/miniprojects/project3/data/syllable_dict_explanation.docx'\n",
    "}\n",
    "\n",
    "def download_file(file_path):\n",
    "    url = url_dict[file_path]\n",
    "    print('Start downloading...')\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024 * 1024 * 1024):\n",
    "                f.write(chunk)\n",
    "    print('Complete')\n",
    "\n",
    "download_file('shakespeare.txt')\n",
    "download_file('spenser.txt')\n",
    "download_file('syllable_dict.txt')\n",
    "download_file('about_syllable_dict.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages \\& Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# grab all poems and separate them by word\n",
    "with open('shakespeare.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "poem_pattern = r'\\s*(\\d+)\\s*(.*?)\\s*(?=^\\s*\\d+|\\Z)'  # chatGPT\n",
    "poem_matches = re.findall(poem_pattern, text, re.DOTALL | re.MULTILINE)\n",
    "poems = []\n",
    "for match in poem_matches:\n",
    "    poems.append(match[1].strip())\n",
    "\n",
    "# hyphens and apostrophes treated as joining two parts of a word\n",
    "# and punctuation ,.?!:; are treated as separated tokens\n",
    "pattern = r'([\\w\\'-]+\\b|[,.?!:;])'\n",
    "all_poem_word_list = []\n",
    "for poem in poems:\n",
    "    words = re.findall(pattern, poem)\n",
    "    all_poem_word_list.append([word.lower() for word in words])\n",
    "print(f'Number of poems: {len(all_poem_word_list)}')\n",
    "\n",
    "# Generate the word to index mapping\n",
    "word_to_idx = {}\n",
    "idx = 0\n",
    "for poem in all_poem_word_list:\n",
    "    for obs in poem:\n",
    "        if word_to_idx.get(obs) is None:\n",
    "            word_to_idx.update({obs: idx})\n",
    "            idx += 1\n",
    "word_to_idx.update({'END': idx})\n",
    "idx_to_word = {v: k for k, v in word_to_idx.items()}\n",
    "print(f'Number of unique observations (including END and punctuation): {len(word_to_idx)}')\n",
    "\n",
    "all_observations = []\n",
    "for poem in all_poem_word_list:\n",
    "    all_observations.append([word_to_idx.get(word) for word in poem] + [word_to_idx.get('END')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from set6hmm import *\n",
    "\n",
    "HMM = unsupervised_HMM(all_observations, n_states=10, N_iters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM.end = [word_to_idx.get('END')]\n",
    "emission = HMM.generate_emission(160)   # ~average length\n",
    "for emit in emission[0]:\n",
    "    print(idx_to_word.get(emit), end=' ')\n",
    "print()\n",
    "word_to_idx.get('END')\n",
    "print(f'Length of this emission: {len(emission[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
